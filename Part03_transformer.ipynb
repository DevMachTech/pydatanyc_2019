{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Transformer and BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Vaswani et al., [Attention is All you Need.](https://papers.nips.cc/paper/7181-attention-is-all-you-need) NIPS 2017: 5998-6008\n",
    "- Devlin et al., [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.](https://www.aclweb.org/anthology/N19-1423/) NAACL-HLT (1) 2019: 4171-4186\n",
    "\n",
    "---\n",
    "\n",
    "- [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)\n",
    "- [The Illustrated BERT, ELMo ...](https://jalammar.github.io/illustrated-bert/)\n",
    "- [The Annotated Transformer](http://nlp.seas.harvard.edu/2018/04/03/attention.html)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1996, 2047, 4068, 3199, 1006, 2022, 2099, 1007, 2097, 2330, 2574, 1012]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids = tokenizer.encode('The new Berlin airport (BER) will open soon.')\n",
    "token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'new',\n",
       " 'berlin',\n",
       " 'airport',\n",
       " '(',\n",
       " 'be',\n",
       " '##r',\n",
       " ')',\n",
       " 'will',\n",
       " 'open',\n",
       " 'soon',\n",
       " '.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(token_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import utils\n",
    "\n",
    "gnad_train, gnad_test = utils.load_gnad()\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# turn all the data into integer indices\n",
    "y_train = label_encoder.fit_transform(gnad_train.category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 3, 6, ..., 7, 1, 4])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "def doc2bert(doc, tokenizer):\n",
    "    tokens = tokenizer.tokenize(doc)[:510]  # NOTE: that's 510 SUBword tokens, not 510 tokens from the original document\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    \n",
    "    # pad everything to 512\n",
    "    if len(token_ids) < 510:\n",
    "        token_ids = token_ids + [0] * (510 - len(token_ids))\n",
    "        \n",
    "    return [tokenizer.cls_token_id] + token_ids + [tokenizer.sep_token_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "token_ids = (doc2bert(x_, tokenizer) for x_ in gnad_train.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, RandomSampler, DataLoader\n",
    "\n",
    "X_train = torch.LongTensor(list(token_ids))\n",
    "y_train = torch.LongTensor(y_train)\n",
    "\n",
    "batch_size = 8\n",
    "data_train = TensorDataset(X_train, y_train)\n",
    "sampler = RandomSampler(data_train)\n",
    "train_dataloader = DataLoader(data_train, sampler=sampler, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  101, 10296,   118,  ...,     0,     0,   102],\n",
       "         [  101,   112, 10915,  ...,   179, 19093,   102],\n",
       "         [  101, 10445, 35350,  ...,   119, 38141,   102],\n",
       "         ...,\n",
       "         [  101, 10445, 15877,  ...,     0,     0,   102],\n",
       "         [  101, 23244, 52332,  ..., 64826, 10726,   102],\n",
       "         [  101, 10915, 10298,  ..., 12471, 42085,   102]]),\n",
       " tensor([5, 3, 6,  ..., 7, 1, 4]))"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 521/521 [00:00<00:00, 49585.49B/s]\n",
      "100%|██████████| 714314041/714314041 [01:30<00:00, 7904448.45B/s] \n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "bert = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased', num_labels=len(torch.unique(y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have quick look at what the output from looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0162,  0.0039,  0.1008,  0.0674, -0.0679, -0.0271,  0.0286,  0.2357,\n",
       "         -0.1319],\n",
       "        [ 0.1414,  0.0765,  0.1642,  0.3456, -0.2813,  0.0801, -0.2042,  0.1813,\n",
       "         -0.0446],\n",
       "        [ 0.1205,  0.0798,  0.1975,  0.2624, -0.2067,  0.0496, -0.1636,  0.1453,\n",
       "         -0.0393],\n",
       "        [ 0.1747,  0.0619,  0.1261,  0.2841, -0.3193,  0.0542, -0.2113,  0.2201,\n",
       "         -0.0830]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output, *_ = bert(X_train[:4])\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1065, 0.1086, 0.1197, 0.1157, 0.1011, 0.1053, 0.1113, 0.1370, 0.0948],\n",
       "        [0.1196, 0.1121, 0.1224, 0.1467, 0.0784, 0.1125, 0.0847, 0.1245, 0.0993],\n",
       "        [0.1180, 0.1133, 0.1274, 0.1360, 0.0851, 0.1099, 0.0888, 0.1210, 0.1006],\n",
       "        [0.1257, 0.1123, 0.1197, 0.1402, 0.0767, 0.1114, 0.0854, 0.1315, 0.0971]],\n",
       "       grad_fn=<ExpBackward>)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "F.log_softmax(output, dim=1).exp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's going on here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "from transformers.optimization import WarmupLinearSchedule\n",
    "\n",
    "num_epochs = 5\n",
    "\n",
    "# pass the parameters of the classifier head ONLY to the optimizer\n",
    "params = [p for n, p in bert.named_parameters() if 'classifier.' in n]\n",
    "optimizer = AdamW(params, lr=3e-5, correct_bias=False)\n",
    "\n",
    "num_total_steps = num_epochs * (len(train_dataloader.sampler) // batch_size)\n",
    "num_warmup_steps = int(num_total_steps * 0.15)\n",
    "scheduler = WarmupLinearSchedule(optimizer, warmup_steps=num_warmup_steps, t_total=num_total_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Rate Schedule\n",
    "## Warmup Linear Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mattilyra/.local/share/virtualenvs/pydatanyc_2019-b2AkOBOU/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_learning_rate(num_warmup_steps):\n",
    "    scheduler = WarmupLinearSchedule(optimizer, warmup_steps=num_warmup_steps, t_total=num_total_steps)\n",
    "    learning_rates = []\n",
    "    for i in range(num_total_steps):\n",
    "        learning_rates.append(scheduler.get_lr())\n",
    "        scheduler.step()\n",
    "    plt.plot(learning_rates);\n",
    "    plt.xlabel('Iteration');\n",
    "    plt.ylabel('Learning Rate');\n",
    "\n",
    "plot_learning_rate(int(num_total_steps * 0.05))\n",
    "plot_learning_rate(int(num_total_steps * 0.10))\n",
    "plot_learning_rate(int(num_total_steps * 0.15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Classification with BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b1670acd71a41e0904df0a63865b871",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=5, style=ProgressStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8285715f6a5946359184c6eddf70a262",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Mini-batch', max=1415, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40e480eb0fb94e908757d4a7361ee816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Mini-batch', max=1415, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f603617f41af4a428abb134f9b16c9a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Mini-batch', max=1415, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef1df7816cf24e589db98bb262d377b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Mini-batch', max=1415, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c1feb2a5b054328a778f31e6c0d85fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Mini-batch', max=1415, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook as tqdmn\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "# Use a GPU if one is available\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "bert.to(DEVICE)\n",
    "\n",
    "for _ in tqdmn(range(num_epochs), total=num_epochs, desc=\"Epoch\"):\n",
    "    steps = tqdmn(train_dataloader,\n",
    "                  total=X_train.size()[0] // train_dataloader.batch_size + 1,\n",
    "                  desc='Mini-batch')\n",
    "    train_loss = 0\n",
    "    for i_step, batch in enumerate(steps):\n",
    "        batch_X, batch_y = (b.to(DEVICE) for b in batch)\n",
    "        loss, *_ = bert(batch_X, labels=batch_y)\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        clip_grad_norm_(bert.parameters(), 1.0)\n",
    "        steps.set_postfix_str(f'avg. loss {train_loss / (i_step + 1):.4f}')\n",
    "        \n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "bert.to('cpu')\n",
    "torch.save(bert.to('cpu'), 'bert-20news-5epochs-HEAD.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "del batch_X, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "X_test, y_test = zip(*[([tokenizer.cls_token_id] + tokenize(x, tokenizer) + [tokenizer.sep_token_id],\n",
    "                         map_label(y_idx))\n",
    "                        for x, y_idx in zip(data_test['data'], data_test['target'])])\n",
    "label_map = {label: idx for idx, label in enumerate(set(y_test))}\n",
    "y_test = [label_map[y_] for y_ in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import SequentialSampler\n",
    "from torch.nn import functional as F\n",
    "\n",
    "X_test = torch.LongTensor(X_test)\n",
    "\n",
    "batch_size = 4\n",
    "data_test = TensorDataset(X_test)\n",
    "sampler = SequentialSampler(data_test)\n",
    "test_dataloader = DataLoader(data_test, sampler=sampler, batch_size=batch_size)\n",
    "\n",
    "bert.eval()\n",
    "bert.to(DEVICE)\n",
    "pred = []\n",
    "for x, *_batch in test_dataloader:\n",
    "    x = x.to(DEVICE)\n",
    "    pred_, *_ = bert(x)\n",
    "    _, pred_ = F.log_softmax(pred_, dim=1).exp().max(dim=1)\n",
    "    pred.extend(pred_.cpu().numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         soc       0.00      0.00      0.00       398\n",
      "         rec       0.00      0.00      0.00      1590\n",
      "         alt       0.05      0.08      0.06       319\n",
      "         sci       0.00      0.00      0.00      1579\n",
      "        misc       0.00      0.00      0.00       390\n",
      "        talk       0.30      0.18      0.22      1301\n",
      "        comp       0.27      0.87      0.42      1955\n",
      "\n",
      "    accuracy                           0.26      7532\n",
      "   macro avg       0.09      0.16      0.10      7532\n",
      "weighted avg       0.12      0.26      0.15      7532\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/share/virtualenvs/pydatanyc_2019-QOOn-cei/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.classification_report(y_test, pred, target_names=list(label_map.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                Linear SVM with parameter tuning\n",
    "\n",
    "                  precision    recall  f1-score   support\n",
    "\n",
    "            comp       0.84      0.87      0.86      1955\n",
    "             soc       0.73      0.71      0.72       398\n",
    "            talk       0.74      0.77      0.75      1301\n",
    "             sci       0.78      0.73      0.76      1579\n",
    "            misc       0.82      0.76      0.79       390\n",
    "             rec       0.79      0.86      0.83      1590\n",
    "             alt       0.62      0.41      0.49       319\n",
    "\n",
    "        accuracy                           0.79      7532\n",
    "       macro avg       0.76      0.73      0.74      7532\n",
    "    weighted avg       0.79      0.79      0.79      7532\n",
    "    \n",
    "---\n",
    "\n",
    "      BERT with fine-tuning the whole transformer stack\n",
    "\n",
    "                  precision    recall  f1-score   support\n",
    "\n",
    "             soc       0.55      0.70      0.61       398\n",
    "             rec       0.82      0.69      0.75      1590\n",
    "             alt       0.02      0.08      0.03       319\n",
    "             sci       0.21      0.09      0.12      1579\n",
    "            misc       0.81      0.55      0.65       390\n",
    "            talk       0.63      0.58      0.60      1301\n",
    "            comp       0.79      0.85      0.82      1955\n",
    "\n",
    "        accuracy                           0.55      7532\n",
    "       macro avg       0.54      0.51      0.51      7532\n",
    "    weighted avg       0.60      0.55      0.57      7532\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dce8f4eb0e5480f96cd175c8b5e8dc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=5, style=ProgressStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea231822127b4f6197d68dd4786d78dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Mini-batch', max=1415, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6597f5d45812427e83ddd335dfa756d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Mini-batch', max=1415, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5d050185b4b4077b36274063ae3ed37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Mini-batch', max=1415, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0c0fcb81a1341c384d5ffda695a4111",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Mini-batch', max=1415, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbbda6f2345249a7bcc153e0294a8099",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Mini-batch', max=1415, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "from transformers.optimization import WarmupLinearSchedule\n",
    "from transformers import BertForSequenceClassification\n",
    "from transformers import AdamW\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdmn\n",
    "\n",
    "num_epochs = 5\n",
    "bert = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(torch.unique(y_train)))\n",
    "params = [p for n, p in bert.named_parameters()]  # if .classifier in n]\n",
    "optimizer = AdamW(params, lr=3e-5, correct_bias=False)\n",
    "\n",
    "num_total_steps = num_epochs * (len(train_dataloader.sampler)\n",
    "                              // batch_size)\n",
    "num_warmup_steps = int(num_total_steps * 0.15)\n",
    "scheduler = WarmupLinearSchedule(optimizer,\n",
    "                                 warmup_steps=num_warmup_steps,\n",
    "                                 t_total=num_total_steps)\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "bert.to(DEVICE)\n",
    "\n",
    "for _ in tqdmn(range(num_epochs), total=num_epochs, desc=\"Epoch\"):\n",
    "    steps = tqdmn(train_dataloader,\n",
    "                  total=X_train.size()[0] // train_dataloader.batch_size + 1,\n",
    "                  desc='Mini-batch')\n",
    "    train_loss = 0\n",
    "    for i_step, batch in enumerate(steps):\n",
    "        batch_X, batch_y = (b.to(DEVICE) for b in batch)\n",
    "        loss, *_ = bert(batch_X, labels=batch_y)\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        clip_grad_norm_(bert.parameters(), 1.0)\n",
    "        steps.set_postfix_str(f'avg. loss {train_loss / (i_step + 1):.4f}')\n",
    "        \n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "bert.to('cpu')\n",
    "torch.save(bert.to('cpu'), 'bert-20news-5epochs-ALL.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import SequentialSampler\n",
    "from torch.nn import functional as F\n",
    "\n",
    "X_test = torch.LongTensor(X_test)\n",
    "\n",
    "batch_size = 4\n",
    "data_test = TensorDataset(X_test)\n",
    "sampler = SequentialSampler(data_test)\n",
    "test_dataloader = DataLoader(data_test, sampler=sampler, batch_size=batch_size)\n",
    "\n",
    "bert.eval()\n",
    "bert.to(DEVICE)\n",
    "pred = []\n",
    "for x, *_batch in test_dataloader:\n",
    "    x = x.to(DEVICE)\n",
    "    pred_, *_ = bert(x)\n",
    "    _, pred_ = F.log_softmax(pred_, dim=1).exp().max(dim=1)\n",
    "    pred.extend(pred_.cpu().numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         soc       0.55      0.70      0.61       398\n",
      "         rec       0.82      0.69      0.75      1590\n",
      "         alt       0.02      0.08      0.03       319\n",
      "         sci       0.21      0.09      0.12      1579\n",
      "        misc       0.81      0.55      0.65       390\n",
      "        talk       0.63      0.58      0.60      1301\n",
      "        comp       0.79      0.85      0.82      1955\n",
      "\n",
      "    accuracy                           0.55      7532\n",
      "   macro avg       0.54      0.51      0.51      7532\n",
      "weighted avg       0.60      0.55      0.57      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.classification_report(y_test, pred, target_names=list(label_map.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Author: Olivier Grisel <olivier.grisel@ensta.org>\n",
    "#         Peter Prettenhofer <peter.prettenhofer@gmail.com>\n",
    "#         Mathieu Blondel <mathieu@mblondel.org>\n",
    "# License: BSD 3 clause\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "import logging\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier(tol=1e-3)),\n",
    "])\n",
    "\n",
    "# uncommenting more parameters will give better exploring power but will\n",
    "# increase processing time in a combinatorial way\n",
    "parameters = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    # 'vect__max_features': (None, 5000, 10000, 50000),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "    # 'tfidf__use_idf': (True, False),\n",
    "    # 'tfidf__norm': ('l1', 'l2'),\n",
    "    'clf__max_iter': (20,),\n",
    "    'clf__alpha': (0.00001, 0.000001),\n",
    "    'clf__penalty': ('l2', 'elasticnet'),\n",
    "    # 'clf__max_iter': (10, 50, 80),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 120 out of 120 | elapsed:  4.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1630.918s\n",
      "\n",
      "Best score: 0.827\n",
      "Best parameters set:\n",
      "\tclf__alpha: 1e-05\n",
      "\tclf__max_iter: 20\n",
      "\tclf__penalty: 'elasticnet'\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__ngram_range: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "data = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "def map_label(label_idx):\n",
    "    return data['target_names'][label_idx].split('.')[0]\n",
    "\n",
    "y_names = list(map(map_label, data.target))\n",
    "label_map = {label: idx for idx, label in enumerate(set(y_names))}\n",
    "y = [label_map[y_] for y_ in y_names]\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters, cv=5, n_jobs=3, verbose=1)\n",
    "\n",
    "grid_search.fit(data.data, y)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "data_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))\n",
    "y_test = [label_map[map_label(y_)] for y_ in data_test.target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        comp       0.84      0.87      0.86      1955\n",
      "         soc       0.73      0.71      0.72       398\n",
      "        talk       0.74      0.77      0.75      1301\n",
      "         sci       0.78      0.73      0.76      1579\n",
      "        misc       0.82      0.76      0.79       390\n",
      "         rec       0.79      0.86      0.83      1590\n",
      "         alt       0.62      0.41      0.49       319\n",
      "\n",
      "    accuracy                           0.79      7532\n",
      "   macro avg       0.76      0.73      0.74      7532\n",
      "weighted avg       0.79      0.79      0.79      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test,\n",
    "                                    grid_search.best_estimator_.predict(data_test.data),\n",
    "                                    target_names=list(label_map.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# German News Categorisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])?  y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_gnad\n",
    "\n",
    "gnad_train, gnad_test = load_gnad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Sport</td>\n",
       "      <td>21-Jähriger fällt wohl bis Saisonende aus. Wie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Kultur</td>\n",
       "      <td>'Erfundene Bilder zu Filmen, die als verloren ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Web</td>\n",
       "      <td>Der frischgekürte CEO Sundar Pichai setzt auf ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Wirtschaft</td>\n",
       "      <td>Putin: \"Einigung, dass wir Menge auf Niveau vo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Inland</td>\n",
       "      <td>Estland sieht den künftigen österreichischen P...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     category                                               text\n",
       "0       Sport  21-Jähriger fällt wohl bis Saisonende aus. Wie...\n",
       "1      Kultur  'Erfundene Bilder zu Filmen, die als verloren ...\n",
       "2         Web  Der frischgekürte CEO Sundar Pichai setzt auf ...\n",
       "3  Wirtschaft  Putin: \"Einigung, dass wir Menge auf Niveau vo...\n",
       "4      Inland  Estland sieht den künftigen österreichischen P..."
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnad_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=3)]: Done 120 out of 120 | elapsed: 12.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('vect',\n",
       "                                        CountVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.int64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        preprocessor=None,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_accents=None,\n",
       "                                                        tok...\n",
       "                                                      shuffle=True, tol=0.001,\n",
       "                                                      validation_fraction=0.1,\n",
       "                                                      verbose=0,\n",
       "                                                      warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=3,\n",
       "             param_grid={'clf__alpha': (1e-05, 1e-06), 'clf__max_iter': (20,),\n",
       "                         'clf__penalty': ('l2', 'elasticnet'),\n",
       "                         'vect__max_df': (0.5, 0.75, 1.0),\n",
       "                         'vect__ngram_range': ((1, 1), (1, 2))},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters, cv=5, n_jobs=3, verbose=1)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(gnad_train.category)\n",
    "grid_search.fit(gnad_train.text, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if BERT can do better than that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "         Etat       0.94      0.76      0.84        67\n",
      "       Inland       0.81      0.84      0.83       102\n",
      "International       0.89      0.83      0.86       151\n",
      "       Kultur       0.91      0.89      0.90        54\n",
      "     Panorama       0.81      0.84      0.82       168\n",
      "        Sport       0.99      0.98      0.99       120\n",
      "          Web       0.92      0.91      0.91       168\n",
      "   Wirtschaft       0.82      0.87      0.85       141\n",
      " Wissenschaft       0.87      0.96      0.92        57\n",
      "\n",
      "     accuracy                           0.88      1028\n",
      "    macro avg       0.88      0.88      0.88      1028\n",
      " weighted avg       0.88      0.88      0.88      1028\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "y_test = label_encoder.transform(gnad_test.category)\n",
    "\n",
    "\n",
    "print(metrics.classification_report(y_test,\n",
    "                                    grid_search.best_estimator_.predict(gnad_test.text),\n",
    "                                    target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "token_ids = (doc2bert(x_, tokenizer) for x_ in gnad_train.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, RandomSampler, DataLoader\n",
    "\n",
    "X_train = torch.LongTensor(list(token_ids))\n",
    "y_train = torch.LongTensor(y)\n",
    "\n",
    "batch_size = 8\n",
    "data_train = TensorDataset(X_train, y_train)\n",
    "sampler = RandomSampler(data_train)\n",
    "train_dataloader = DataLoader(data_train, sampler=sampler, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AdamW, BertForSequenceClassification\n",
    "from transformers.optimization import WarmupLinearSchedule\n",
    "\n",
    "num_epochs = 5\n",
    "bert = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased', num_labels=len(torch.unique(y_train)))\n",
    "params = [p for n, p in bert.named_parameters()]\n",
    "optimizer = AdamW(params, lr=3e-5, correct_bias=False)\n",
    "\n",
    "\n",
    "num_total_steps = num_epochs * (len(train_dataloader.sampler) // batch_size)\n",
    "num_warmup_steps = int(num_total_steps * 0.15)\n",
    "scheduler = WarmupLinearSchedule(optimizer, warmup_steps=num_warmup_steps, t_total=num_total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b1670acd71a41e0904df0a63865b871",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=5, style=ProgressStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8285715f6a5946359184c6eddf70a262",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Mini-batch', max=1415, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40e480eb0fb94e908757d4a7361ee816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Mini-batch', max=1415, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f603617f41af4a428abb134f9b16c9a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Mini-batch', max=1415, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef1df7816cf24e589db98bb262d377b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Mini-batch', max=1415, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c1feb2a5b054328a778f31e6c0d85fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Mini-batch', max=1415, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook as tqdmn\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "# Use a GPU if one is available\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "bert.to(DEVICE)\n",
    "\n",
    "for _ in tqdmn(range(num_epochs), total=num_epochs, desc=\"Epoch\"):\n",
    "    steps = tqdmn(train_dataloader,\n",
    "                  total=X_train.size()[0] // train_dataloader.batch_size + 1,\n",
    "                  desc='Mini-batch')\n",
    "    train_loss = 0\n",
    "    for i_step, batch in enumerate(steps):\n",
    "        batch_X, batch_y = (b.to(DEVICE) for b in batch)\n",
    "        loss, *_ = bert(batch_X, labels=batch_y)\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        clip_grad_norm_(bert.parameters(), 1.0)\n",
    "        steps.set_postfix_str(f'avg. loss {train_loss / (i_step + 1):.4f}')\n",
    "        \n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "rise": {
   "theme": "white"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
